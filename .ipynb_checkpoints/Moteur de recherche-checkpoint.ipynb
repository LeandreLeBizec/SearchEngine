{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0880d0cb",
   "metadata": {},
   "source": [
    "# Moteur de recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3971d6",
   "metadata": {},
   "source": [
    "Le moteur de recherche prend en entré un vecteur ( la requête ) et compare ce vecteur avec les vecteurs des documents ( via un calcul de distance entre ces vecteurs par exemple ). On renvoie ensuite la lsite des documents triés dans l'ordre croissant, ainsi, le document avec la plus faible distance sera affiché en premier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2231e12",
   "metadata": {},
   "source": [
    "## I - comparer la distance entre 2 vecteurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cc732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "import numpy as np #pour cosine(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a37197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40824829046386296\n"
     ]
    }
   ],
   "source": [
    "vec1 = [0,1,1,0,1]\n",
    "vec2 = [0,1,0,1,0]\n",
    "\n",
    "d = np.dot(vec1,vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "print(d)\n",
    "\n",
    "def calculDistance(vec1, vec2):\n",
    "    d = np.dot(vec1,vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641a9c4",
   "metadata": {},
   "source": [
    "On importe un corpus de document, qui regroupe tous les documents sur lesquels on veut tester notre moteur de recherche. Chaque document de ce corpus est mis sous forme vectoriel\n",
    "\n",
    "On importe ensuite le corpus des requêtes contenant toutes les requêtes sous forme vectorielle\n",
    "\n",
    "On peut ainsi calculer la distance entre le vecteur d'une requête et chaque documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc16e709",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpusDocument' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#importer corpusDocument\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#importer coprusRequete\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#requete = requete que l'on veut tester\u001b[39;00m\n\u001b[1;32m      5\u001b[0m Res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcorpusDocument\u001b[49m :\n\u001b[1;32m      7\u001b[0m     Res\u001b[38;5;241m.\u001b[39mappend(calculDistance(doc,requete))\n\u001b[1;32m      9\u001b[0m Res\u001b[38;5;241m.\u001b[39msort()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpusDocument' is not defined"
     ]
    }
   ],
   "source": [
    "#importer corpusDocument\n",
    "#importer coprusRequete\n",
    "#requete = requete que l'on veut tester\n",
    "\n",
    "Res = []\n",
    "for doc in corpusDocument :\n",
    "    Res.append(calculDistance(doc,requete))\n",
    "    \n",
    "Res.sort()\n",
    "\n",
    "Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "887a9115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AD695049',\n",
       " 'I',\n",
       " 'be',\n",
       " 'not',\n",
       " ',',\n",
       " 'nor',\n",
       " 'have',\n",
       " 'I',\n",
       " 'ever',\n",
       " 'pretend',\n",
       " 'to',\n",
       " 'be',\n",
       " ',',\n",
       " 'an',\n",
       " 'expert',\n",
       " 'on',\n",
       " 'microfiche',\n",
       " '.',\n",
       " ' ',\n",
       " 'nevertheless',\n",
       " ',',\n",
       " 'when',\n",
       " 'I',\n",
       " 'be',\n",
       " 'invite',\n",
       " 'to',\n",
       " 'address',\n",
       " 'the',\n",
       " 'Third',\n",
       " 'Annual',\n",
       " 'Northeastern',\n",
       " 'DDC',\n",
       " '/',\n",
       " 'Industry',\n",
       " 'Users',\n",
       " 'Conference',\n",
       " 'in',\n",
       " 'Waltham',\n",
       " ',',\n",
       " 'Massachusetts',\n",
       " 'in',\n",
       " 'April',\n",
       " 'of',\n",
       " '1968',\n",
       " 'I',\n",
       " 'have',\n",
       " 'the',\n",
       " 'temerity',\n",
       " 'to',\n",
       " 'attempt',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'what',\n",
       " 'I',\n",
       " 'as',\n",
       " 'a',\n",
       " 'user',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'have',\n",
       " 'in',\n",
       " 'a',\n",
       " 'fiche',\n",
       " 'reader',\n",
       " '.',\n",
       " ' ',\n",
       " '(',\n",
       " \"'\",\n",
       " 'towards',\n",
       " 'a',\n",
       " 'Uniform',\n",
       " 'Federal',\n",
       " 'Report',\n",
       " 'Numbering',\n",
       " 'System',\n",
       " 'and',\n",
       " 'a',\n",
       " 'Cuddly',\n",
       " 'Microfiche',\n",
       " 'reader',\n",
       " '--',\n",
       " 'two',\n",
       " 'Modest',\n",
       " 'Proposals',\n",
       " '.',\n",
       " \"'\",\n",
       " 'revise',\n",
       " 'September',\n",
       " '1968',\n",
       " '.',\n",
       " ' ',\n",
       " 'AD-669204',\n",
       " ')']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req1 = \"Specific advantages of computerized index systems\"\n",
    "doc1 = \"Editions of the Dewey Decimal Classifications The present study is a history of the DEWEY Decimal Classification. The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad.\"\n",
    "doc2 = \"AD695049 I am not, nor have I ever pretended to be, an expert on microfiche.  Nevertheless, when I was invited to address the Third Annual Northeastern DDC/Industry Users Conference in Waltham, Massachusetts in April of 1968 I had the temerity to attempt to describe what I as a user would like to have in a fiche reader.  ('Towards a Uniform Federal Report Numbering System and a Cuddly Microfiche Reader--Two Modest Proposals.' Revised September 1968.  AD-669204)\"\n",
    "CorpusDoc = [doc1,doc2]\n",
    "\n",
    "dico=[]\n",
    "\n",
    "#transformer la requete en une liste de token et ajouter au dico des lemmes de la requete\n",
    "tabreq1=[]\n",
    "req1nlp = nlp(req1)\n",
    "for token in req1nlp:\n",
    "    tabreq1.append(token.lemma_)\n",
    "    \n",
    "#ajouter au dico de tous les lemmes des doc       \n",
    "for doc in CorpusDoc:       \n",
    "    docnlp = nlp(doc)\n",
    "    for token in docnlp :\n",
    "        if(token.lemma_ not in dico):\n",
    "            dico.append(token.lemma_)\n",
    "\n",
    "            \n",
    "#Doc1\n",
    "tabdoc1=[]\n",
    "doc1nlp = nlp(doc1)\n",
    "for token in doc1nlp:\n",
    "    tabdoc1.append(token.lemma_)\n",
    "    if(token.lemma_ not in dico):\n",
    "        dico.append(token.lemma_)\n",
    "\n",
    "#Doc2\n",
    "tabdoc2=[]\n",
    "doc2nlp = nlp(doc2)\n",
    "for token in doc2nlp:\n",
    "    tabdoc2.append(token.lemma_)\n",
    "    if(token.lemma_ not in dico):\n",
    "        dico.append(token.lemma_)\n",
    "\n",
    "tabdoc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25cde2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08770580193070293, 0.17541160386140586]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformer la requete en vecteur            \n",
    "vecreq=[0]*len(dico)\n",
    "for i in range(len(dico)):\n",
    "    if(dico[i] in tabreq1):\n",
    "        vecreq[i]=1\n",
    "\n",
    "\n",
    "#transformer le doc1 en vecteur\n",
    "vecdoc1=[0]*len(dico)\n",
    "for i in range(len(dico)):\n",
    "    if(dico[i] in tabdoc1):\n",
    "        vecdoc1[i]=1\n",
    "\n",
    "#transformer le doc2 en vecteur\n",
    "vecdoc2=[0]*len(dico)\n",
    "for i in range(len(dico)):\n",
    "    if(dico[i] in tabdoc2):\n",
    "        vecdoc2[i]=1\n",
    "            \n",
    "corpusDocumentVec=[vecdoc1,vecdoc2]\n",
    "Res = []\n",
    "for doc in corpusDocumentVec :\n",
    "    Res.append(calculDistance(doc,vecreq))\n",
    "    \n",
    "Res.sort()\n",
    "\n",
    "Res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6126a0c",
   "metadata": {},
   "source": [
    "## II - En entrée matrice du score des mots par documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e898310d",
   "metadata": {},
   "source": [
    "Ce que l'on reçoit est une matrice ( ligne : doc, colone : mot ) ayant le score de chaque mot par document "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7bdda4",
   "metadata": {},
   "source": [
    "il faut donc récréer les vecteurs et refaire comme avant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
